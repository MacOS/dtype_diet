{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from dtype_diet.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dtype_diet\n",
    "\n",
    ">  Attempt to shrink Pandas `dtypes` without losing data so you have more RAM (and maybe more speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install dtype_diet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a fork of https://github.com/ianozsvald/dtype_diet to continue supoprt and develop the library with approval from the original author @ianozsvald.\n",
    "\n",
    "\n",
    "Status - early alpha, written in 2 hours on a Sunday. Suggestions welcome, I may accept PRs but you're better off asking first (via a bug report) with the suggestion in case it isn't where I want to take the library. I'm also very happy to have \"Thanks\" posted via bugs too if this helps you out :-)\n",
    "\n",
    "This tool checks each column to see if larger dtypes (e.g. 8 byte `float64` and `int64`) could be shrunk to smaller `dtypes` without causing any data loss. \n",
    "Dropping an 8 byte type to a 4 (or 2 or 1 byte) type will keep halving the RAM requirement for that column.  Categoricals are proposed for `object` columns which can bring significant speed and RAM benefits.\n",
    "\n",
    "Whilst working on the [2nd edition of High Performance Python](https://www.goodreads.com/book/show/49828191-high-performance-python) with Micha Gorelick I wrote on RAM reduction in the Using Less RAM chapter for Pandas and NumPy and I wanted to write a tool like this, but didn't have time (heck, writing the 2nd edition took 9 months!). So, I got to write this tool after publication instead.\n",
    "\n",
    "Here's an example (see Notebook: [example_sell_prices_ram_shrinkage.ipynb](example_sell_prices_ram_shrinkage.ipynb) ) on a Kaggle dataset showing a reduction of 957 -> 85MB:\n",
    "\n",
    "![sell_prices after dtype_dtype](example_sell_prices.png)\n",
    "\n",
    "Recommendations:\n",
    "\n",
    "* Run `report_on_dataframe(your_df)` to get recommendations\n",
    "* Consider if Categoricals will save you RAM (see Caveats below)\n",
    "* Consider if f32 or f16 will be useful (see Caveats - f32 is _probably_ a reasonable choice unless you have huge ranges of floats)\n",
    "* Consider if int32, int16, int8 will be useful (see Caveats - overflow may be an issue)\n",
    "* Look at https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.convert_dtypes.html which recommends Pandas nullable dtype alternatives (e.g. to avoid promoting an int64 with NaN items to float64, instead you get Int64 with NaNs and no data loss)\n",
    "* Look at Extension arrays like https://github.com/JDASoftwareGroup/rle-array (thanks @repererum [for the tweet](https://twitter.com/crepererum/status/1267441357339201536))\n",
    "\n",
    "Look at `__main__` and try `report_on_dataframe(your_df)` to get a printed report - no changes are made to your dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "### CLI\n",
    "\n",
    "```bash\n",
    "$ rm -f dtype_diet.py\n",
    "$ wget https://raw.githubusercontent.com/ianozsvald/dtype_diet/master/dtype_diet.py\n",
    "```\n",
    "\n",
    "### Notebook\n",
    "\n",
    "```bash\n",
    "%%bash\n",
    "rm -f dtype_diet.py\n",
    "wget https://raw.githubusercontent.com/ianozsvald/dtype_diet/master/dtype_diet.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source file/Notebook cell\n",
    "\n",
    "```python\n",
    "import dtype_diet\n",
    "...(for rest of the usage example see notebook mention in previous section)...\n",
    "```\n",
    "\n",
    "# example run on a made-up dataframe in __main__\n",
    "\n",
    "```\n",
    "dtype_diet$ python dtype_diet.py \n",
    "Given a dataframe, check for lowest possible conversions:\n",
    "Smallest non-breaking converstion per column:\n",
    "a (int64) currently taking 928 bytes, to save 700 bytes try `a.astype(int8)`\n",
    "b (int64) currently taking 928 bytes, to save 600 bytes try `b.astype(int16)`\n",
    "c (int64) currently taking 928 bytes, to save 400 bytes try `c.astype(int32)`\n",
    "d (float64) currently taking 928 bytes, to save 600 bytes try `d.astype(float16)`\n",
    "e (float64) currently taking 928 bytes, to save 400 bytes try `e.astype(float32)`\n",
    "str_a (object) currently taking 6,328 bytes, to save 5,958 bytes try `str_a.astype(category)`\n",
    "str_b (object) currently taking 6,018 bytes - no suggestion\n",
    "```\n",
    "\n",
    "## Caveats\n",
    "\n",
    "* reduced numeric ranges might lead to overflow (TODO document)\n",
    "* category dtype can have unexpected effects e.g. need for observed=True in groupby (TODO document)\n",
    "* f16 is likely to be simulated on modern hardware so calculations will be 2-3* slower than on f32 or f64\n",
    "* we could do with a link that explains binary representation of float & int for those wanting to learn more\n",
    "\n",
    "## Development \n",
    "\n",
    "There's a bunch of interesting notes in the initial Tweet I sent out: https://twitter.com/ianozsvald/status/1267129298646941696 (thanks to all who replied).\n",
    "\n",
    "### Releases\n",
    "\n",
    "Run `pytest dtype_diet.py` (better yet - add more tests!). Push to github.\n",
    "\n",
    "### Contributors\n",
    "\n",
    "* Antony Milbourne https://github.com/amilbourne\n",
    "* Mani https://github.com/neomatrix369\n",
    "\n",
    "### Setup\n",
    "\n",
    "```\n",
    "$ conda create -n dtype_diet python=3.8 pandas jupyter pyarrow pytest\n",
    "$ conda activate dtype_diet\n",
    "```\n",
    "\n",
    "# Contributing\n",
    "The repository is developed with `nbdev`, a system for developing library with notebook.\n",
    "\n",
    "Make sure you run this if you want to contribute to the library. For details, please refer to nbdev documentation (https://github.com/fastai/nbdev)\n",
    "```\n",
    "nbdev_install_git_hooks\n",
    "```\n",
    "\n",
    "Some other useful commands\n",
    "```\n",
    "nbdev_build_docs\n",
    "nbdev_test_nbs\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
